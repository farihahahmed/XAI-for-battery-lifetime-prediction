# Novel explainable AI for predicting battery lifetime: comparable accuracy to state- of-the-art black-box models

# Authors: Farihah Ahmed, Mauricio Hernandez

# Battery lifetime prediction is a critical problem for electric vehicle (EV) users’ range maximization and battery manufacturers’ faster research and development (R&D). While a growing subfield of accurate AI has been applied to predict the nonlinear degradation mechanisms of batteries, there is a lack of explainable AI (XAI) in the field, inhibiting the deployment of these models due to missing trust and confidence from end- users in the models’ black-box decision-making. The goal of this study was to build an XAI model using the ‘explainable’ concept of Euclidean Distance that would overcome the accuracy-explainability tradeoff. We hypothesized that using this XAI approach, we would be able to develop an improved, deployable battery lifetime prediction model that is both accurate and explainable to end-users. Using 3 different explainable models, 4 different data splits, and 4 approaches (1 regression task, 3 classification tasks), and hyperparameter tuning, our lowest Classification Error was 4%--better than state-of-the- art models—and our lowest regression Mean Percent Error was 11.8%--comparable to state-of-the-art models. This work’s implications are three-fold: it can (1) increase trust in EV consumers and battery manufacturers using this model--overcoming a massive barrier to the wider deployment of Lithium-ion batteries, (2) reveal greater insights about how battery lifetime is determined--helping battery manufacturers accelerate the R&D process, (3) is a call for greater deployment of XAI in all fields, as we have demonstrated that it is indeed possible to have both explainable and accurate AI, in order to increase societal trust in AI.
